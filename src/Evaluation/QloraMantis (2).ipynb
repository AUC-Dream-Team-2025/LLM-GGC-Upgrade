{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGsazwSCsXwa",
        "outputId": "d92a5aa2-fcec-4e99-9d10-5e2c885abc53"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/bin/python -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!pip install flash-attn --no-build-isolation\n",
        "!pip install git+https://github.com/TIGER-AI-Lab/Mantis.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONaNbIBqsXwc",
        "outputId": "05dd62f1-1a7c-4ded-b657-8922d1c3cce2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC8kWtdlsXwc"
      },
      "outputs": [],
      "source": [
        "from mantis.models.mllava import chat_mllava\n",
        "from PIL import Image\n",
        "import flash_attn_2_cuda\n",
        "import torch\n",
        "import json\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM, GenerationConfig, BitsAndBytesConfig\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Upyv2hAT18Sg",
        "outputId": "16a090a5-4fea-4b38-d15b-26d8b87cb979"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip uninstall bitsandbytes\n",
        "!pip install bitsandbytes\n",
        "!pip install transformers bitsandbytes torch\n",
        "import torch\n",
        "print(torch.cuda.is_available())  # Should return True\n",
        "print(torch.version.cuda)        # Should match your CUDA version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "37f40aea581743dcb45350457c4d3ecf",
            "163de887ce92466cb9b4c5a74b1e8dbc",
            "7650cb26b89f4fd8b729874dad390a64",
            "93ab6465ff0c40c89204f159b07c11ba",
            "2fc3bf170c3240b1a2b6d59d27e794da",
            "dfa5330062b64ec39ba8503ea03e360f",
            "5b9b1468ef834111a06bbaebf20c22a7",
            "c51685892a424489b751b59741722e3f",
            "97d4a87b44ac4facb033923f3839df1e",
            "3f4a97e9c09d4bfb865771cb27ab6cdd",
            "fb88b9a3c462489d842f89ad2923cc69"
          ]
        },
        "id": "-PhXdEdTsXwd",
        "outputId": "597a5197-edfe-46a0-cee0-99b2b32ae823"
      },
      "outputs": [],
      "source": [
        "from mantis.models.mllava import chat_mllava\n",
        "from PIL import Image\n",
        "import json\n",
        "from transformers import AutoProcessor, AutoModel, BitsAndBytesConfig\n",
        "\n",
        "# Define the model path\n",
        "model_path = \"TIGER-Lab/Mantis-8B-Idefics2\"  # Replace with the correct model path\n",
        "\n",
        "# Load the processor\n",
        "processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n",
        "\n",
        "# Load the model with 4-bit quantization\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "model = AutoModel.from_pretrained(\n",
        "    model_path,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_config,\n",
        "    trust_remote_code=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X7C6_7JsXwd",
        "outputId": "5575b9bc-b08c-479a-d183-8ac04bb9b652"
      },
      "outputs": [],
      "source": [
        "from mantis.models.mllava import chat_mllava\n",
        "from PIL import Image\n",
        "import flash_attn_2_cuda\n",
        "import json\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM, GenerationConfig, BitsAndBytesConfig\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
        "\n",
        "# Example usage of GenerationConfig (if needed)\n",
        "generation_config = GenerationConfig(\n",
        "    max_length=128,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    do_sample=True\n",
        ")\n",
        "\n",
        "print(\"GenerationConfig imported and defined successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvwwSsghsXwd",
        "outputId": "8e60fc89-656d-495b-bc6c-fdae847d8ebb"
      },
      "outputs": [],
      "source": [
        "from mantis.models.mllava import chat_mllava\n",
        "from PIL import Image\n",
        "import flash_attn_2_cuda\n",
        "import json\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM, GenerationConfig, BitsAndBytesConfig\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
        "\n",
        "# Define LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    r=8,  # Rank of the LoRA update matrices\n",
        "    lora_alpha=32,  # Scaling factor for LoRA updates\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],  # Target modules to apply LoRA\n",
        "    lora_dropout=0.1,  # Dropout probability for LoRA\n",
        "    bias=\"none\",  # Whether to add bias\n",
        "    task_type=\"CAUSAL_LM\"  # Task type (e.g., causal language modeling)\n",
        ")\n",
        "\n",
        "print(\"LoRA configuration defined successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSX5W8ew7PKV",
        "outputId": "4984f776-2390-4e60-bcaa-241f989f5914"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVhh2zNjsXwe",
        "outputId": "6649d86f-268b-4b6a-c732-dbacccc20ca9"
      },
      "outputs": [],
      "source": [
        "from transformers import Pix2StructProcessor, Pix2StructForConditionalGeneration\n",
        "from PIL import Image\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Define the path to the zip file\n",
        "zip_file_path = \"/png.zip\"  # Replace with the actual path to your zip file\n",
        "extracted_folder = \"/extracted_images\"  # Folder to extract images\n",
        "\n",
        "# Extract the zip file\n",
        "os.makedirs(extracted_folder, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder)\n",
        "\n",
        "print(f\"Extracted images to {extracted_folder}\")\n",
        "\n",
        "# %% Load JSON file for processing\n",
        "input_file = \"/test_human.json\"  # Replace with your input JSON file path\n",
        "output_file = \"output.json\"  # File to save generated answers\n",
        "\n",
        "with open(input_file, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# %% Initialize Pix2Struct for chart QA\n",
        "processor = Pix2StructProcessor.from_pretrained('google/deplot')\n",
        "model = Pix2StructForConditionalGeneration.from_pretrained('google/deplot')\n",
        "\n",
        "# Process each entry in the JSON file\n",
        "previous_file_name = \"\"\n",
        "\n",
        "# List to store results\n",
        "results = []\n",
        "\n",
        "# %% Iterate through each entry in the JSON file\n",
        "for entry in data:\n",
        "    file_name = entry[\"imgname\"]\n",
        "    file_path = \"/extracted_images/png/{}\".format(file_name)\n",
        "    question = entry[\"query\"]\n",
        "    expected_answer = entry[\"label\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJrMn5NnCF9n",
        "outputId": "0728179c-aaec-4944-b8cb-ac6f8cfaf599"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from transformers import Pix2StructProcessor, Pix2StructForConditionalGeneration\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Initialize variables\n",
        "previous_file_name = \"\"\n",
        "results = []\n",
        "\n",
        "# Initialize loss tracking\n",
        "losses = []\n",
        "epochs = []\n",
        "\n",
        "# Counters for accuracy\n",
        "correct_human = 0\n",
        "total_human = 0\n",
        "correct_augmented = 0\n",
        "total_augmented = 0\n",
        "\n",
        "# Simulate multiple epochs (for demonstration purposes)\n",
        "for epoch in range(1, 6):  # Simulate 5 epochs\n",
        "    epoch_loss = 0  # Track total loss for the epoch\n",
        "    epoch_correct = 0  # Track correct predictions for the epoch\n",
        "    epoch_total = 0  # Track total predictions for the epoch\n",
        "\n",
        "    # Iterate through each entry in the dataset (assuming `data` is a list of entries)\n",
        "    for entry in data:\n",
        "        file_name = entry[\"imgname\"]\n",
        "        file_path = \"/extracted_images/png/{}\".format(file_name)  # Replace with the actual path to your images\n",
        "        question = entry[\"query\"]\n",
        "        expected_answer = entry[\"label\"]\n",
        "\n",
        "        # Reload pipeline if the file name changes\n",
        "        if file_name != previous_file_name:\n",
        "            print(f\"Loading new image: {file_name}\")\n",
        "            processor = Pix2StructProcessor.from_pretrained('google/deplot')\n",
        "            model = Pix2StructForConditionalGeneration.from_pretrained('google/deplot')\n",
        "            previous_file_name = file_name  # Update tracking variable\n",
        "\n",
        "        # Open the image and verify it's valid\n",
        "        try:\n",
        "            image = Image.open(file_path)\n",
        "            width, height = image.size  # Validate image dimensions (width and height must not be None)\n",
        "            if width is None or height is None:\n",
        "                print(f\"Invalid image dimensions for {file_path}\")\n",
        "                continue  # Skip this image if dimensions are invalid\n",
        "        except (IOError, SyntaxError) as e:\n",
        "            print(f\"Error loading image {file_path}: {e}\")\n",
        "            continue  # Skip this image and move to the next one\n",
        "\n",
        "        # Process the image and query\n",
        "        inputs = processor(images=image, text=\"Using the chart provided, answer the question: {}\".format(question), return_tensors=\"pt\")\n",
        "        predictions = model.generate(**inputs, max_new_tokens=512)\n",
        "        generated_answer = processor.decode(predictions[0], skip_special_tokens=True)\n",
        "\n",
        "        print(\"Question:\", question)\n",
        "        print(\"Generated Answer:\", generated_answer)\n",
        "        print(\"Expected Answer:\", expected_answer)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        is_correct = generated_answer.strip().lower() == expected_answer.strip().lower()\n",
        "        epoch_total += 1\n",
        "        if is_correct:\n",
        "            epoch_correct += 1\n",
        "\n",
        "        # Simulate a loss metric (e.g., string similarity or token overlap)\n",
        "        loss = 1.0 if not is_correct else 0.0  # Loss is 1 if incorrect, 0 if correct\n",
        "        epoch_loss += loss\n",
        "\n",
        "        # Track results for test_human and test_augmented\n",
        "        if \"human\" in file_name:  # Assuming filenames indicate the dataset\n",
        "            total_human += 1\n",
        "            if is_correct:\n",
        "                correct_human += 1\n",
        "        elif \"augmented\" in file_name:  # Assuming filenames indicate the dataset\n",
        "            total_augmented += 1\n",
        "            if is_correct:\n",
        "                correct_augmented += 1\n",
        "\n",
        "        # Store the result\n",
        "        results.append({\n",
        "            \"imgname\": file_name,\n",
        "            \"query\": question,\n",
        "            \"label\": expected_answer,\n",
        "            \"generated_answer\": generated_answer,\n",
        "            \"is_correct\": is_correct,\n",
        "            \"loss\": loss\n",
        "        })\n",
        "\n",
        "    # Track epoch loss and accuracy\n",
        "    losses.append(epoch_loss / epoch_total)  # Average loss for the epoch\n",
        "    epochs.append(epoch)\n",
        "    print(f\"Epoch {epoch}: Loss = {losses[-1]:.4f}, Accuracy = {epoch_correct / epoch_total * 100:.2f}%\")\n",
        "\n",
        "# Calculate overall accuracy\n",
        "total_overall = total_human + total_augmented\n",
        "correct_overall = correct_human + correct_augmented\n",
        "accuracy_human = correct_human / total_human if total_human > 0 else 0\n",
        "accuracy_augmented = correct_augmented / total_augmented if total_augmented > 0 else 0\n",
        "accuracy_overall = correct_overall / total_overall if total_overall > 0 else 0\n",
        "\n",
        "# Print accuracies\n",
        "print(f\"Accuracy on test_human: {accuracy_human * 100:.2f}%\")\n",
        "print(f\"Accuracy on test_augmented: {accuracy_augmented * 100:.2f}%\")\n",
        "print(f\"Overall accuracy: {accuracy_overall * 100:.2f}%\")\n",
        "\n",
        "# Save results to a JSON file\n",
        "output_file = \"output_results.json\"\n",
        "with open(output_file, \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(f\"Results saved to {output_file}\")\n",
        "\n",
        "# Plot losses over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, losses, label=\"Loss\", marker='o')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Time\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "163de887ce92466cb9b4c5a74b1e8dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa5330062b64ec39ba8503ea03e360f",
            "placeholder": "​",
            "style": "IPY_MODEL_5b9b1468ef834111a06bbaebf20c22a7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2fc3bf170c3240b1a2b6d59d27e794da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37f40aea581743dcb45350457c4d3ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_163de887ce92466cb9b4c5a74b1e8dbc",
              "IPY_MODEL_7650cb26b89f4fd8b729874dad390a64",
              "IPY_MODEL_93ab6465ff0c40c89204f159b07c11ba"
            ],
            "layout": "IPY_MODEL_2fc3bf170c3240b1a2b6d59d27e794da"
          }
        },
        "3f4a97e9c09d4bfb865771cb27ab6cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b9b1468ef834111a06bbaebf20c22a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7650cb26b89f4fd8b729874dad390a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c51685892a424489b751b59741722e3f",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97d4a87b44ac4facb033923f3839df1e",
            "value": 4
          }
        },
        "93ab6465ff0c40c89204f159b07c11ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f4a97e9c09d4bfb865771cb27ab6cdd",
            "placeholder": "​",
            "style": "IPY_MODEL_fb88b9a3c462489d842f89ad2923cc69",
            "value": " 4/4 [01:43&lt;00:00, 22.86s/it]"
          }
        },
        "97d4a87b44ac4facb033923f3839df1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c51685892a424489b751b59741722e3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa5330062b64ec39ba8503ea03e360f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb88b9a3c462489d842f89ad2923cc69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
